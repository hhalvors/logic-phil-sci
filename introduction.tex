\chapter{Introduction}

%% PUT ALL THE PROVOCATIVE STUFF IN THE INTRODUCTION

Some people say that philosophy never makes progress.  In fact,
professional philosophers say that more frequently --- and feel it
more acutely --- than anyone else.  At the beginning of the 20th
century, some philosophers felt it so acutely that they decided to
cast all previous philosophy on the scrap heap, and to rebuild from
scratch.  ``Why shouldn't philosophy be like science?'', they asked.
``Why can't it also make genuine progress?''  You might have thought
that they would have located the problem in the lack of empirical
data.  While the sciences can do experiments, and thereby refute bad
ideas (such as ``leeches cure disease''), philosophers can say all
sorts of crazy things, without any fear of empirical refutation.  But
the early 20th century philosophers realized that the possibility of
empirical refutation is not the {\it sine qua non} of a progressive
science.

The 19th century had been a time of enormous progress in the field of
pure mathematics, with theorem after theorem pouring from the pens of
the mathematicians in Germany, France, Italy, Russia, England, etc..
``What is the magic that these mathematicians have found?'' asked the
philosophers at the beginning of the 20th century.  ``How is it that
they figured out what the concept of `infinity' means, while
philosophers such as Hegel could only say that the concept led to
paradox?''  At least these are the questions that one philosopher
started asking: a young man named \emph{Bertrand Russell}.

Russell commenced study in mathematics at Trinity College, Cambridge
in 1890.  At the time --- at least according to Russell himself ---
the dominant philosophical outlook at Cambridge was Hegelian.  With
his craving for absolute clarity and rigour, Russell could not abide
Hegelian philosophy.  Toward the end of the 19th century, he found his
ally in G.E. Moore (1873--1958), who shared Russell's philosophical
predilections.  Thus was analytic philosophy born.

Despite similarities in overall outlook, Russell and Moore differed in
their choice of methodological tools.  While Moore always stayed
closer to ``ordinary language'', Russell believed that the defect in
Hegel's philosophy was its reliance on outmoded logical methods.  To
fix philosophy, though Russell, we first have to fix logic.

Russell was indeed well-positioned to bring the ``new logic'' to bear
on philosophical discussions.  Not only had he received an excellent
education via the Cambridge mathematics {\it tripos}, but he entered
the scene at an especially propitious time.  In the years preceding
Russell's entry to Cambridge, several major developments had occurred
in the foundations of mathematics:
\begin{itemize}
\item George Boole had clarified the structure of logical relations
  between propositions.
\item Georg Cantor had clarified and ramified the concept of infinity,
  thereby setting the stage for the development of the new
  mathematical theory of sets.
\item \emph{Gottlob Frege} had proposed a {\it Begriffsschrift}, i.e.\
  a language of thought.
\item Italian mathematicians, such as Peano and Pieri, had axiomatized
  major portions of classical mathematics such as arithmetic and
  projective geometry.
\item \emph{David Hilbert} --- building on a long German tradition of
  analytic geometry --- had proposed that all mathematical symbols and
  terminology needed to be ``de-interpreted'', so that proofs could be
  judged based on purely formal criteria.  Thus was born the
  discipline of ``meta-mathematics.''
\end{itemize}
Despite all the progress that had been made on the mathematical front,
it took Russell's peculiar genius to see that these developments
called for a fundamental change in the methods of philosophical
inquiry.  As with previous western philosophers such as Descartes,
Hume, and Leibniz, Russell believed that philosophy could only
flourish if it kept pace with developments in the sciences --- if only
because philosophy must be responsive to the questions that arise in
scientific practice.

The story of the birth of analytic philosophy is indeed rich and
multifaceted, but we can only touch lightly upon it, for our objective
is to enter the story mid-stream.  We will have to leave the closer
analysis of 19th century developments for another time.  At present,
the important point is merely that for Russell, philosophical inquiry
ought to walk hand in hand with scientific inquiry.  And we shouldn't
construe ``scientific inquiry'' so narrowly as to include only those
sciences that are primarily directed towards the systematization of
empirical phenomena.  To the contrary, philosophy has a particularly
close relationship with the deductive sciences, and when the deductive
sciences advance, philosophy can either advance with them --- or it
can flounder.  Russell's goal was to realign philosophy back with the
trajectory of the sciences, especially the deductive sciences, after
the disastrous 19th century divorce.

Russell's stance on these issues is no doubt controversial, and it is
the prerogative of his philosophical descendants to wonder whether he
didn't send us off in the wrong direction.  But the goal of this book
is not to dismantle Russell's program, which by the beginning of the
21st has all but unwound.  We are not living under the reign of
Russell, but in the aftermath of Russell's reign.  Instead, our goal
is to understand the consequences that Russell's maneuver --- to place
mathematical logic at the core of philosophy --- had on discussions in
20th century philosophy.  While some philosophers might argue that
20th century philosophy erred in being too closely aligned with
mathematical logic, we will take a more charitable view.  Instead of
developing a global criticism of the presuppositions of that
methodology, we will inquire into specific applications of it.

The specific applications of this methodology have been numerous.  In
fact, a case could be made that {\it most} major developments in 20th
century analytic philosophy turned in some way or other on a result in
mathematical logic, and philosophers' interpretation of the
consequences of that result.  In the earliest cases, Russell used the
new logic to argue (effectively?) against what he called the
ontological excesses of Hegel, and of lesser known 19th century
philosophers such as Meinong.  Those early cases are indeed very well
known, and we won't discuss them further in this book.  We will be
more concerned with cases where the role of formal logic is a bit more
subtle, and a bit less well understood.  Let's turn first to one of
the most significant moments in 20th century philosophy, when Quine
``demolished'' logical positivism.

During his years as an undergraduate student at Oberlin, \emph{Willard
  van Orman Quine} had become entranced with Russell's mathematical
logic.  After getting his PhD from Harvard in 1932, Quine set out to
learn from the European logicians --- the first generation descendants
of Frege.  Here Quine encountered the infamous Vienna Circle at an
extremely auspicious time, just when \emph{Rudolf Carnap} was setting
his {\it Wissenschaftslogik} program into motion.  Quine quickly
became Carnap's strongest critic.  As the story is often told ---
especially to undergraduate students --- Quine was single-handedly
responsible for the demise of Carnap's program, and for logical
positivism more generally.

Quine's philosophical arguments against positivism have been sifted
and re-sifted over the past sixty years.  My goal in this book isn't
really to give the ``latest and greatest'' interpretation of these
arguments.  Instead, I will be focusing on a less well known aspect of
this story, viz.\ the role that results in mathematical logic played
in this debate.  For example, it doesn't seem to be widely known that
Quine already had developed proto-criticisms of the analytic-synthetic
distinction in the late 1930s --- criticisms which only came to the
fore in his famous ``Two dogmas of empiricism'' (1951).  For example,
in 1940, Quine and Goodman published a proof which shows, in their own
words, that any synthetic axiom can be reconstrued as an analytic
axiom.  Whatever one may think of Quine's later arguments against
analyticity, there is no doubt, historically speaking, that this
result played some role in Quine's arriving at the conclusion that
there is no genuine distinction between analytic and synthetic
sentences.  And it would only be reasonable to think that {\it our}
stance on the analytic-synthetic distinction should be responsive to
what this mathematical result is supposed to show.  What if, you might
wonder, Quine had misunderstood the upshot of his own result?  Might
Quine's view have been more similar to Carnap's if he had not made one
or two simple mistakes in the way he interpreted mathematical results?

Of course, Quine was massively influential in 20th century philosophy
--- and not just in the views he held, but in the methods he used for
arriving at those views.  In short, the Quinean methodology --- in its
roughest form --- looks something like this:
\begin{enumerate}
\item One proves some theorem $T$ in logical metatheory (or finds some
  such theorem in the literature).
\item One argues that $T$ has certain philosophical consequences,
  e.g.\ makes a certain view untenable.  Then, because $T$ is a {\it
    theorem} one finds the strongest kind of support for these
  philosophical consequences.
\end{enumerate}
As we've already seen with Quine, the supposed philosophical
consequences of a logical theorem $T$ can be rather profound.  To say
that there is no legitimate analytic-synthetic distinction is not a
minor point, of little concern to the person on the street.  To the
contrary, if that claim is true, then it has {\it profound}
implications for our view of human knowledge.  One virtue, then, of
the Quinean methodology is that it provides the strongest kind of
human motivation for learning mathematical logic.  If apparently
abstruse results in mathematical logic can make all the difference to
our view of what we know, or what we ought to do, then everybody has a
duty to learn some mathematical logic!  Or, if not everyone has a duty
to learn mathematical logic, then at least everybody has a duty to
{\it listen} to those philosophers who understand mathematical logic.

I have not made anything like a systematic attempt to collect {\it
  all} applications of this Quinean methodology in 20th century
philosophy.  Suffice it to say that there have been hundreds, or even
thousands, of such applications --- and they continue in philosophy
departments around the world, and on the pages of distguished analytic
philosophy journals.  But I didn't have to work hard to collect seven
or eight notable cases of this Quinean methodology, where the supposed
philosophical consequences were quite profound.  By ``profound
consequences'' here, I'm talking about the kind of philosophical
consequences that change a person's perception of ``what life is all
about''.  For example, if you could convince me that science cannot
possibly lead reliably to truths about unobservable things, then (I
must admit) I would have a hard time encouraging students to devote
their lives to the difficult labors involved in a life of scientific
research.  Certainly, one might try to motivate the pursuit of science
on purely pragmatic grounds (e.g.\ developing new vaccines), but some
of us (the present author included) are so radically selfish as to be
impervious to such calls.

So, let's look at a few paradigm cases of this Quinean methodology.
Surely the most striking example of this Quinean methodology --- of
getting a lot of philosophy out of a little bit of mathematics ---
would be \emph{Hilary Putnam's} famous ``model-theoretic argument''
\citep{putnam1977,putnam-models}.  Here Putnam cites a moderately
advanced result of metalogic: the L{\"o}wenheim-Sk{\o}lem theorem,
which shows that if a theory has an infinite model, then that theory
has models of all infinite cardinalities.  (I'm not being completely
precise in this introduction, but I will be in later chapters.)  This
result is no doubt interesting, but not obviously in any {\it deep}
philosophical sense.  And yet, the philosophical juice that Putnam
squeezed out of this theorem was so abundant that we are still mopping
it up today --- forty years after he publicized these astounding
claims.

Ironically, the very same Putnam had previously used the Quinean
methodology to push in the opposite direction, i.e.\ in the direction
of metaphysical and scientific realism.  In the 1960s, Putnam was one
of the leaders of the gang working to dismantle the remaining edifice
of logical positivism.  One of the key components of this edifice was
the distinction between ``purely theoretical statements'' and
``observation statements'', a distinction which is presupposed by any
view of science that assigns an epistemically peculiar role to the
latter kind of sentences.  Although there were many arguments against
this distinction, coming from various directions, it is not suprising
that some of the most decisive such arguments were the ones that
hinted that mathematical logic could not countenance such a
distinction.  In particular, we hear from Putnam, \emph{Richard Boyd},
\emph{Bas van Fraassen}, et al.,\ that ``the empirical content of a
theory {\it cannot} be isolated syntactically''.  In other words, the
claim is that mathematical logic simply cannot make sense of this
distinction --- hence philosophers must do without the distinction,
and at least in the case of Boyd and Putnam, this means that the
warrant for believing a scientific theory cannot flow primarily from
from bottom (the empirical part) to the top (the theoretical part).
The movement here is subtle, but it amounts to a profound shift in
attitude toward scientific theories.  In fact, this shift is no less
radical than the move from Kant's empiricism to Hegel's unapologetic
rationalism --- only in the case at hand, the proponents of the shift
claim that it is mandated by formal logic.

Now, not every philosopher was bamboozled by logic into radical,
indiscriminate scientific and metaphysical realism.  In particular,
those philosophers with a little bit more logical sophistication
understood what the game was, and they had some moves of their own.
The shining example here is Bas van Fraassen, who ceded that standard
(syntactic) metalogic was no friend to empiricism --- and then in good
philosophical fashion, van Fraassen turned the {\it modus ponens} into
a {\it modus tollens}.  That is, van Fraassen located the problem not
in empiricism, but in the logic that was being used to frame the
discussion.  However, van Fraassen was too sophisticated to locate the
problem in mathematical logic, per se.  Instead, said van Fraassen,
the problem is an overly restrictive view of mathematical logic,
according to which a legitimate explication needs to be carried out
with the tools of {\it syntax}.  Indeed, van Fraassen claimed that the
notion of empirical content {\it does} admit a semantic explication;
and with this explication in hand, empiricism can be defended against
indiscriminate realism.  Thus, in this case, both the joust and the
parry were carried on within an explicitly meta-logical framework.

By this time, scientific realism had gained a lot of momentum.
Indeed, the major names in the field --- your Salmons, and
Churchlands, and Boyds --- were all self-proclaimed {\it scientific
  realists}.  Van Frassen was the rare exception to the general trend.
The realists proceeded to attack van Fraassen's picture on several
fronts.  \cite{musgrave} chose to press on van Fraassen's notion of
the empirical content of a theory.  However, the debate at this stage
had lost direct contact with metalogic.  None of the parties involved
seemed concerned with the question of whether a precise explication of
the concept was possible.  Instead, the argument went forward in the
absence of any agreed upon standards of what would count as an
adequate defense.  That is, until \cite{dick} came back with yet
another criticism of the distinction.  The reply from van Fraassen
pushes the debate back onto the syntax-semantics distinction:
\begin{quote}
  We point to a flaw in these and similar criticisms: they proceed
  from the syntactic view of scientific theories whereas constructive
  empiricism is and has always been wedded to the semantic view, a
  fact that has consequences for the characterization of empirical
  adequacy and hence for the formulation that constructive empiricism
  favours. \citep{muller} \end{quote} As you know, anytime somebody
says that a philosophical position depends on adopting the semantic
view of theories, we see a red flag.  Since syntax and semantics are
mirror images of each other, if a distinction can be drawn at a
semantic level, then it can also be drawn at a syntactic level.
Indeed, \cite{turney} had argued some years earlier that van
Fraassen's semantic notion of empirical content could be translated
into a syntactic notion.

This is not to say that van Fraassen doesn't have a point against
Dicken and Lipton.  Indeed, we can charitably interpret van Fraassen's
statements about semantics as saying that philosophers need to
sophisticate their formal analyses --- the the first, ham-fisted
syntactic analysis might need to give way to a more sophisticated
analysis.  In the 1970s, the preferred tool for these more
sophisticated analyses was {\it model theory}; hence van Fraassen's
appeal to the semantic view of theories.  But mathematics --- and
metamathematics --- have continued to progress in the past forty
years.  It is now completely clear that there is no fundamental divide
between ``syntactic'' and ``semantic'' approaches to theories --- no
more than there is a fundamental divide between algebra and geometry.
... while semantics can be indispensible for us humans, {\it
  indispensible} for seeing the truth of certain facts, he benefit of
hindsight, we can see now that ``syntactic methods'' are far more
powerful than the philosophers of the 1970s had reason to believe.
With the knowledge we have today, it's possible to locate the source
of the debate not in the syntax/semantics distinction, but where it
always belonged --- as a battle of fundamentally different attitudes
about human agency and its relation to scientific knowledge.


\section{The semantic view of theories}

Since the 1970s, philosophical discusssions of science have been
profoundly influenced by this little debate about the place of syntax
and semantics.  Here I am thinking primarily of the {\it methodology}
of the philosophy of science.  Prior to the criticisms --- by Putnam,
van Fraassen, et al. --- of the ``syntactic view of theories'',
philosophical discussions of science frequently drew upon new results
in mathematical logic.  As was pointed out by van Fraassen
particularly, these discussions frequently degenerated, as
philosophers found themselves hung up on seemingly trivial questions,
e.g.\ whether the observable consequences of a recursively axiomatized
theory are also recursively axiomatizable.  Part of the shift from
syntactic to semantic methods was supposed to be a shift toward a more
faithful construal of science in practice.  In other words,
philosophers were supposed to start asking the questions that arise in
the practice of science, rather than the questions that were suggested
by an obsessive attachment to mathematical logic.

I will be the first to acknowledge that the semantic move had many
healthy consequences in terms of philosophers engaging more closely
with actual scientific theories.  Since the 1970s, amazing
foundational research has been conducted.
\begin{itemize}
\item Research on the foundations of spacetime physics by Larry Sklar,
  John Earman, David Malament, John Norton, Tim Maudlin, Gordon Belot,
  etc.
\item Research on the foundations of quantum theory by Bas van
  Fraassen, Richard Healey, David Albert, Michael Redhead, Jeremy
  Butterfield, Rob Clifton, Miklos Redei, Laura Ruetsche, etc.
\item Research on the foundations of statistical physics by Larry
  Sklar, John Earman, David Albert, Charlotte Werndl, etc.
\item Research on the foundations of evolutionary biology by Elisabeth
  Lloyd, John Beatty, Paul Thompson, Kim Sterelny, etc.
\end{itemize}
There is no doubt that philosophers have done a better job of
understanding ``actual science'' in the past forty years than they did
in the preceding years, not to speak of the 19th century.  For
example, in the past forty years, philosophers have been on the front
lines discussing the quantum measurement problem.  And would they have
done that if they had been hung up on the sort of syntactic questions
that occupied Carnap in {\it Logische Syntax der Sprache}
\citeyearpar{carnap1934}.  Most likely they would not.

Thus, it is a little bit tempting to associate logical syntax with a
``degenerating research program'' in philosophy of science, and to
associate logical semantics with a ``progressive research program.''
However, we must be careful --- as usual --- not to confuse
correlation with causation.  There may well be other reasons why
philosophers since 1970 have been more involved with ``real science''
than philosophers in the 1950s.  Perhaps one reason is simply that
there is a larger labor force, since there are more people employed in
philosophy departments.  (Consider, for example, that Pittsburgh and
Indiana opened ``history and philosophy of science'' departments in
the 1960s.)  In any case, we should be careful not to confuse quantity
with quality: just because there are more philosophers talking about
science doesn't mean that this interaction is better for philosophy of
for the sciences.  Indeed, it seems that scientists are less
interested now in philosophy than they were forty years ago.  Thus,
there is a danger that philosophers are creating a caricature of
science to discuss amongst themselves.

Nonetheless, there has also been an unfortunate consequence of the
attitude that ``semantics solves all'', viz.\ a loss of analytic
rigour, and frequent confusions over whether the topic at hand is
synactic, semantic, or material in nature.  Perhaps the most striking
example of these confusions arises in discussions of symmetries in
physics.  While the topic of symmetry is doubtless a difficult one,
philosophers have made it more difficult by constantly confusing
logical semantics with descriptions of the world, not to speak of
their numerous conflations of the material and formal modes of speech.
Regardless of one's opinions about Carnap's syntax program, a very
strong case can be made that formal logic can be an aid in reducing
confusion.  After all, it was designed precisely with that end in
mind: as a way of representing our thoughts clearly and distinctly.
However, the philosophical pendulum has swung back so far that
philosophers of science rarely turn to formal logic as an aid for
clarification.  Instead, the attitude seems to be that formal logic
can only make things more obscure.

This negative attitude toward formal logic is understandable.
Philosophy graduate students rarely get past a first course in
metalogic.  And that first course in metalogic is often focused around
proving G\"odel's incompleteness theorem --- which means that the
focus is on one specific theory (viz.\ arithmetic), and on a special
class of functions (viz.\ the recursive functions).  This particular
topic is doubtless interesting for its own sake, and yet the tools
that are taught are of little use in most philosophical discussions of
science --- not in discussions of general relativity or quantum
mechanics, and much less so in discussions of evolutionary biology or
cognitive science.  It's no wonder, then, that philosophers of science
have felt that they have more of an affinity toward ``semantic
methods''.  What they really mean is that they have need of a more
broad mathematical toolkit than that offered by 1930s metamathematics.
So be it.  Nonetheless, there is a huge danger of letting the
methodological motive (needing more mathematics) turn into an ideology
(semantics over syntax).  One of the goals of this book is to offer
more of the mathematics that one needs to understand the structure of
science, without promoting an ideology based on the vague distinction
between syntax and semantics.

But we have gotten ahead of the story of logic in 20th century
philosophy.  We left that story with Quine telling Carnap that there
is no feasible notion of ``analytically true sentences'', and with
Putnam telling Carnap that there is no feasible notion of
``observation sentences.''  This story is often told in such a way
that Carnap is made to look like a fool.  But if you think about it,
that is really an odd thing to think.  Human beings of all shapes and
sizes presuppose that it's legitimate to treat some sentences as
analytically true, and that it's legitimate to treat some sentences as
directly confirmable or disconfirmable.  In one very clear sense, the
force of Quine and Putnam's arguments is against philosophers'
attempts to {\it explicate} these notions.

As we saw before, Carnap had self-imposed the constraint that a
philosophical explication of a concept must be {\it syntactic}.  So,
for example, to talk about ``observation sentences,'' one must
construct a corresponding predicate in the language of syntactic
metalogic --- a language whose primitive concepts are things like
``predicate symbol'' and ``binary connective''.  Carnap took a swing
at defining such predicates, and Quine, Putnam, and friends found his
explications to be inadequate.  There are many directions that one
could go from here --- and one of these directions remains largely
unexplored.  First, one can do as Quine and Putnam themselves did:
stick with logical syntax, and change one's philosophical views.
Second, one can do as van Fraassen did: move to logical semantics, and
stick with Carnap's philosophical views.  (To be fair, van Fraassen's
philosophical views are very different than Carnap's --- I only mean
here to indicate that there are certain central respects in which van
Fraassen's philosophical views are closer to Carnap's than to
Quine's.)  The third option is to say: perhaps logical syntax had not
yet reached a fully mature stage in 1950, and perhaps new developments
will make it more feasible to carry out syntactic explications of
philosophical concepts.  That third option is {\it one} of the
objectives of this book, although I hasten to add that I do not share
Carnap's views that led him to demand syntactic explications.

In the 1970s and 1980s many philosophers of science --- following
especially van Fraassen and Suppe --- adopted an {\it ideological}
commitment to a semantic view of theories.  While there were many
explicit statements of this commitment, it was rarely challenged on
philosophical grounds.  (For a rare exception, see \cite{friedman}.)
The attitude of most philosophers of science seemed to be one of
gratitude that the logic police were no longer looking over their
shoulders.  They could no carry on their analyses of particular
theories (such as quantum mechanics), or of particular concepts (such
as scientific explanation), without anybody challenging them on the
formal coherence of the notions they were proposing.  This liberation
from logic probably had many good effects.  But it wasn't good that
philosophers allowed the ideological statements to pass uncriticized
into the literature.  It is only in the past couple of decades that
some of the bad consequences of this ideology have come to the fore.

In the past decadeThese days it seems that not many philosophers carry
forward this ideological commitment.  Nonetheless, ideological
commitments trickle down into practice, and many contemporary
philosophers of science operate as if it is preferable to analyze
theories from a semantic point of view.

[[physicalism]]



A case could be made --- as it will be in this book --- that some of
the most radical shifts of opinion in 20th century philosophy were of
this form.  I claim, among other things, that the shift from
positivism to post-positivism was of this form, as was the shift from
early-Putnam's realism to late-Putnam's antirealism, and the shift to
the semantic view of theories (and the attendant shift of research
aims in philosophy of science).  Since these moves were so important,
it's crucial that we evaluate them carefully.  And that requires close
attention both on the mathematical and the philosophical side.  The
clearer a vision we can achieve of the metalogical results, the
clearer we can be about what philosophical consequences (if any)
follow from them.

%% TO DO: put in something here about equivalence of
%% theories.  Some claim about equivalence based on sticking within
%% single-sorted framework.

\begin{figure}[h]
%   \rotatebox{90}{%
%     \begin{minipage}{\textheight}%
       % your text
\begin{tabular}{l | l | l}
  logic & philosophy & loc \\
  \hline \hline
  translate into empty theory & analytic-synthetic distinction (Quine) & \textbf{\ref{qgood}} \\
  \hline
  translate into empty theory & implicit definition (Quine) \\
  \hline   
  eliminate sorts & ontological monism (Quine)  & \textbf{\ref{quine-sort}} \\
  \hline
  eliminate sorts & internal-external distinction (Quine) \\
  \hline        
  eliminate sorts & against quantifier variance & \textbf{\ref{go-qv}} \\
  \hline  indivisible vocabulary   & against empiricism (Putnam, Boyd) \\
  \hline
  embeddability   & for empiricism (van Fraassen) \\
  \hline 
  Beth's theorem & supervenience implies reduction & \textbf{\ref{go-beth}} \\          
  \hline L{\"o}wenheim-Sk{\o}lem & against realism (Putnam) & \textbf{\ref{putnam}} \\
  \hline
  equivalent geometries  & against realism (Putnam) & \textbf{\ref{go-geometry}} \\
  \hline Ramsification & structural realism & \\
  \hline Ramsification & functionalism & \\ 
  \hline
  %          Beth's theorem & partial interpretation  (van Fraassen)      \\
\end{tabular}
%     \end{minipage}%
%  }%
  % No caption, then the figure number is not changed
\end{figure}

To be fair, I don't mean to say that the philosophers mentioned on the
right explicitly endorse the argument from the metalogical result to
the philosophical conclusion.  In some cases they do; but in other
cases, the philosopher seems rather to {\it presuppose} the
metalogical result, since it has become common knowledge among
philosophers who learned metalogic in graduate school.  So, for
example, most of us were taught single-sorted logic; and we might have
been told that many-sorted logic was an unnecessary complication,
adding no further insight, since (as Quine has pointed out), it is
reducible to single-sorted logic.  Thus are metalogical myths born.
(Quine was right in one sense, and wrong in another sense.  See ??)

The primary aim of this book is to investigate the second maneuver:
how philosophical consequences are supposed to follow from metalogical
theorems.  But in order to do so in a systematic fashion, we also have
to engage directly with the first maneuver, i.e.\ we have to study
these metalogical proofs, and to understand how they work.

I am not a skeptic of all forms of inference (2).  However, I worry
that many individual instances of this inference are invalid, or at
least highly misleading.  The aim of this book is to study these
individual instances, and to see where they might go wrong.  The
following instances are discussed in this book.

The most important debate in the history of 20th century analytic
philosophy was the debate between Carnap and Quine.  As we all know,
20th century analytic philosophy had two major phases: the phase
before Quine's ``Two Dogmas of Empiricism,'' and the phase after it.
In short, before Quine came along, analytic philosophy was headed in
one particular direction, with Carnap as the {\it de facto} leader.
Along came Quine, who supposedly showed that Carnap's way of thinking
was based on some fundamental misconceptions.

We need to remember that Carnap's entire philosophical program was
centered around formal logic.  When Carnap put forward a philosophical
idea, he tied it down to some features of formal logic.  Thus, we need
also to remember that Quine's earliest critiques of Carnap were aimed
at undercutting Carnap's attempt to tether philosophical ideas to
concepts of formal logic.  For example, Carnap would ground a
philosophical distinction in some formal distinction, and then Quine
would argue that there really is no such formal distinction.

%% Review Carnap: (1) frameworks, (2) analytic truths, (3) observation sentences

% [[Quine-Goodman]]




\section{Sweeping aside sorts}

In the late 20th century, many prominent philosophers rejected Quine's
claim that {\it classical first-order logic} provides the preferred
language for regimenting scientific theories (which are the paradigm
example of human knowledge).  Among analytic philosophers at the turn
of the 21st century, the tool of choice was more often some modal
logic (such as S4 and S5) than it was the predicate calculus.

The decline in adherence to the strictures of classical logic can make
it difficult to assess some of Quine's arguments --- in particular,
when those arguments draw upon some facts that are specific to that
logical framework.  However, some of Quine's most pointed criticisms
of the logical positivists involved him invoking features of the
framework of classical FOL.  These Quinean arguments tend to run as
follows: \begin{quote} The logical positivist position presupposes a
  certain distinction.  But first order logic doesn't support that
  distinction.  Therefore, the logical positivist position is
  insupportable. \end{quote} This Quinean move is subtle, and it's not
suprising that those involved in the debate didn't see what exactly
was going on.  We have the benefit of hindsight --- and of a more firm
grasp on the relevant metalogical facts.

As the story is typically told, Quine's ``Two Dogmas'' dealt the death
blow to logical positivism.  However, Carnap presented Quine with a
moving target, as his views continued to develop.  In ``Empiricism,
semantics, and ontology'' \citeyearpar{carnap-eso}, Carnap further
develops the notion of a {\it framework}, which bears striking
resemblances both to the notion of a {\it scientific theory}, and the
even more precise notion of a theory in first-order logic.  Here
Carnap distinguishes two types of questions --- the questions that are
{\it internal} to the framework, and the questions that are {\it
  external} to the framework.  The internal questions are those that
can be posed in the language of the framework, and for which the
framework could (in theory) provide an answer.  In contrast, the
external questions are those that we ask {\it about} a framework.

Carnap's abstract idea can be illustrated by simple examples from
first-order logic.  If we write down a signature $\Sigma$ for a
first-order language, and a theory $T$ in that signature, then a
typical internal question might be something like, ``Does anything
satisfy the predicate $P(x)$?''.  [Of course, the language based on
$\Sigma$ doesn't have these words or question marks.  The question is
simply whethere $\exists xP(x)$.]  In contrast, a typical external
question might be, ``How many predicate symbols are there in
$\Sigma$''?  Thus, the internal/external distinction corresponds
roughly to the older distinction between object- and meta-language
that frames Carnap's discussion in {\it Logische Syntax der Sprache}.

The philosophical point of the internal/external distinction was
supposed to be that one's answers to external questions are not held
to the same standards as one's answers to internal questions.  A
framework includes rules, and an internal question should be answered
in accordance with these rules.  So, to take one of Carnap's favorite
examples, ``Are there numbers?''  can naturally construed as an
external question, since no mathematician is actively investigating
that question.  In other words, ``are there numbers?'' is {\it not} up
for grabs in mathematical science --- instead, it's a presupposition
of mathematical science.  In contrast, ``Is there a greatest prime
number?'' is internal to mathematical practice, i.e.\ it is a question
to which mathematics aspires to give an answer.

Surely most of us can grasp the intuition that Carnap is trying to
develop here.  The external questions must be answered in order to set
up the game of science; the internal questions are answered in the
process of playing the game of science.  But Carnap wants to push this
idea beyond the intuitive level --- he wants to make it a cornestone
of his theory of knowledge.  Thus, Carnap says that we may single out
a certain special class of predicates --- the so-called {\it
  Allw\"orter} --- to label a domain of inquiry.  For example, the
number theorist uses the word ``number'' to pick out her domain of
inquiry --- she doesn't investigate whether something falls under the
predicate ``$x$ is a number''.  In contrast, a number theorist might
investigate whether there are numbers $x,y,z$ such that $x^3+y^3=z^3$;
and she simply doesn't consider whether something other things, which
are not themselves numbers, satisfy this relation.

\cite{quine1951a,quine1960} takes up the attack against Carnap's
internal/external distinction.  While Quine's attack has several
distinct maneuvers, one of the more subtle (and less closely
scrutinized) of his maneuvers is his appeal to metalogic.  In this
case, Quine appeals to the fact that every theory in a language that
has several distinct quantifiers (i.e.\ many-sorted logic) is
equivalent to a theory in a language with a single unrestricted
quantifier.  \begin{quote} It is evident that the question whether
  there are numbers will be a category question only with respect to
  languages which appropriate a separate style of variables for the
  exclusive purpose of referring to numbers.  If our language refers
  to numbers through variables that also take classes other than
  numbers as values, then the question whether there are numbers
  becomes a subclass question. \ldots Even the question whether there
  are classes, or whether there are physical objects becomes a
  subclass question if our language uses a single style of variables
  to range over both sorts of entities.  Whether the statement that
  there are physical objects and the statement that there are black
  swans should be put on the same side of the dichotomy, or on
  opposite sides, comes to depend upon the rather trivial
  consideration of whether we use one style of variables or two for
  physical objects and classes. \end{quote} Thus, suggests Quine,
there is a metalogical fact --- that we can freely choose beween
separate or single styles of variables --- that destroys the purported
distinction between {\it Allw\"orter} and other predicates in our
theories.

We won't weigh in on this issue here, in our introduction.  It would
be premature to do so, because the entire point of this book is to lay
out the mathematical facts in a clear fashion, so that the reader can
judge the philosophical claims for herself.  We need not defer to
Quine's logical expertise when establishing our view on fundamental
philosophical questions.


\bigskip \bigskip











[[TO DO: model isomorphism criterion ... as part of a general
discussiono about equivalence of theories.]]

[[TO DO: Quantifier variance]]




\section{From syntax to semantics}

Besides all the points we've just gone over, and will go through in
greater length in the pages to come, there was a more general
transition in 20th century analytic philosophy that followed the
contours of an important transition in metalogic.

Metalogic in the 20th century underwent two major periods of
development --- a {\it syntactic} period, and a {\it semantic} period.
To help the reader remember this categorization, we could also
associate each period with the name of a major figure.  The syntactic
period is most naturally associated with the German mathematician
\emph{David Hilbert}, and the semantic period is most naturally
associated with the Polish logician \emph{Alfred Tarski}.

In short, metalogic in the earliest part of the 20th century focused
on the analysis of logical languages and the rules that define them
--- the so-called formation and transformation (or deduction) rules.
(These parts of metalogic are now typically classed under the heading
{\it proof theory}, although the focus of proof theory has become more
specific than the examination of all relevant syntactic questions, and
especially questions about the relations between theories.)  Thus, the
early 20th century saw major works of analytic philosophy, such as
Carnap's {\it The Logical Syntax of Language}, which not only followed
the methodology of syntactic metatheory, but which defined the task of
philosophy in terms of concepts drawn from syntactic metatheory.
Roughly speaking, philosophy was supposed to stand to science (and
scientific theories) as syntactic metalogic stands to mathematics (and
mathematical theories).  Carnap explicitly voiced his hope of creating
a metalogic of science in the same way that David Hilbert had created
metamathematics.

When it comes to understanding scientific theories, logical syntax has
the advantage that it demands extreme clarity and caution.  In short,
explicating a concept in logical syntax is almost like writing a
computer program in machine language.  To do so, we must talk about
things like the number of left parentheses, or how to substitute one
variable for another, or how to tabulate the dependencies in the
derivation of a sequent.  To be sure, we can define some properties of
theories, such as consistency, and some relations between theories,
such as one theory being a conservative extension of another.  But in
general, proofs in syntactic metatheory are long, tedious, and
unilluminating.  And when one becomes frustrated, there is a
temptation to think that syntactic metatheory is strictly limited in
the insights it can provide.  One might even start to doubt whether
this syntactic approach is the best way, mathematically speaking, to
model the ``universe of theories.''

In any case, the promise of a purely syntactic metatheory for
mathematics fell into question already in the 1920s when Kurt
G{\"o}del proved the incompleteness of Peano arithmetic.  At the time,
a new generation of logicians realized that not all interesting
questions about theories could be answered merely by looking at
theories ``in themselves'', and without relation to other mathematical
objects.  Instead, they claimed, the interesting questions about
theories include questions about how they might relate to antecedently
understood mathematical objects, such as the universe of sets.  Thus
was born the discipline of logical semantics.  The arrival of this new
approach to metatheory was was heralded by Alfred Tarski's famous
definitions of ``truth in a structure'' and ``model of a theory''.
Thus, after Tarski, to understand a theory $T$, we have more than the
theory {\it qua} syntactic object, we also have a veritable universe
$\mathrm{Mod}(T)$ of models of $T$.

The development of analytic philosophy in the 20th century walked hand
in hand with the development of mathematics --- and with the
development of metamathematics in particular.  With a couple of
notable exceptions.  In mathematics, new techniques don't typically
show that old techniques were ``wrong'', only perhaps that they were
difficult to work with.  So, for example, to study analytic functions
of a real variable, mathematicians now frequently study them within
the richer context of functions of a complex variable.  But it's not
at all that mathematicians have decided that complex numbers are more
fundamental than real numbers, or even that the old techniques have no
use whatsoever.  In short, the new methods typically allow us to say
more things, but not by changing our views about the original things.

An even better example of this procedure in mathematics is the
multi-discipline known as {\it representation theory}.  For some
reason that remains a bit elusive, mathematicians find that they
sometimes can understand objects better if they add structure to these
objects that they do {\it not} intrinsically possess.  I used the word
``multi-discipline'' because there are many representation theories.
There is a representation theory of groups, of algebras, of
$C^*$-algebras, of Boolean algebras, etc..  To take one prominent
example, consider the case of groups.  Roughly speaking, a group $G$
is a set with a binary multiplication operation $\circ$, a unary
inverse operation $-1$, and an identity element $e\in G$.  One might
think that the best way to study $G$ would be to look inside $G$.  But
instead, we might say, consider all homomorphisms $\pi :G\to U(H)$,
where $H$ is a (complex) vector space, and $U(H)$ is the group of all
symmetries of $H$.  Perhaps surprisingly, the collection of all such
representations tells us a lot about $G$, even thought any particular
representation of $G$ on a particular $H$ might tell us very little
about $G$.

Mathematicians see group representation theory as a supplement to
``syntactic'' group theory, not as a substitute or replacement or a
superior account of groups.  However, many philosophers have taken a
radically different attitude toward the relation between semantic
metatheory and syntactic metatheory.  Many philosophers have claimed
that semantic metatheory plays a privileged role --- it replaces
syntactic metatheory, and it gives a better model of the universe of
theories.  At least that's my analysis of the attitudes of many
philosophers in the 1960s through 1990s.  In possession of the
powerful techniques of semantic metatheory, these philosophers argued,
among other things, that:
\begin{enumerate}
\item semantic metatheory has greater conceptual resources than
  syntactic metatheory --- in particular, it can articulate further
  properties of theories, and relations between theories. can say
  about theories that cannot be said in syntactic metatheory.
  \item \end{enumerate}

 \begin{itemize}
  \item The development of logical semantics also seems to have
    resurrected other philosophical positions that had been buried
    alongside of logical positivism.  [[add stuff here about reduction
    --- fetch it from the Beth's theorem section]]

\end{itemize}

\section{Reduction and supervenience}

The early logical positivists --- Schlick, Carnap, Neurath, etc. ---
aspired to the uphold the highest standards of scientific rationality.
Several of them came to believe that commitment to scientific
rationality demands a commitment to physicalism, i.e.\ the thesis that
physical science is the final arbiter on claims of ontology.  In
short, they said that we ought to believe that something exists only
if physics licences that belief.  Of course, we then have to reject
claims about gods, angels, demons, witches, and fairies.  But what are
we supposed to do with the sorts of statements that people make in the
ordinary course of life --- about each other, and about themselves.
For example, if I say, ``I am in pain,'' then I seem to be committed
to the existence of some object ``I'', that has some property ``is in
pain.''  Does physical science license this claim?

The general thesis of physicalism, and the particular thesis that a
person is his body, were not 20th century novelties.  However, it was
a 20th century novelty to attempt to explicate these theses using the
tools of formal logic.  To successfully explicate this concept would
transform it from a vague ideological stance to a sharp scientific
hypothesis.  (There is no suggestion here that the hypothesis would be
empirically verifable --- merely that it would be clear enough to be
vulnerable to counterargument.)

For example, suppose that $r(x)$ denotes the property of being in
pain.  Then it would be natural for the physicalist to propose either
(1) that statements using $r(x)$ are actually erroneous, or (2) that
there is some predicate $\phi (x)$ in the language of fundamental
physics such that $\forall x(r(x)\lra \phi (x))$.  In other words, if
statements using $r(x)$ are legitimate, then $r(x)$ must actually pick
out some underlying physical property $\phi (x)$.

The physicalist will want to clarify what he means by saying that
$\forall x(r(x)\lra \phi (x))$, for even a Cartesian dualist could
grant that this sentence is contingently true.  That is, a Cartesian
dualist might say that there is a purely physical description
$\phi (x)$ which happens, as a matter of contingent fact, to pick out
exactly those things that are in pain.  The reductionist, in contrast,
wants to say more.  He wants to say that there is a more thick
connection between pain experiences and happenings in the physical
world.  At the very least, a reductionist would say that
\[ T^+\: \vdash \: r(x)\lra \phi (x) ,\] where $T^+$ is our most
fundamental theory of the physical world.  That is, to the extent that
ordinary language ascriptions are correct, they can be translated into
true statements of fundamental physics.

This sort of linguistic reductionism seems to have been the favored
view among early 20th century analytic philosophers --- or, at least
among the more scientifically inclined of them.  Certainly, this
linguistic reductionism had vocal proponents, such as U.T. Place and
Herbert Feigl ... By the third quarter of the 20th century, this sort
of hard-core reductionism had fallen out of fashion.  In fact, some of
the leading lights in analytic philosophy --- such as Hilary Putnam
--- had devised master arguments which were taken to demonstrate the
utter implausibility of the reductionist point of view.  Nonetheless,
what had not falled out of favor among analytic philosophers was the
naturalist stance that had found its precise explication in the
reductionist thesis.  Thus, analytic philosophers found themselves on
the hunt for a new, more plausible way to express their naturalistic
sentiments.

There was another movement afoot in analytic philosophy --- a movement
back away from the formal mode, toward the material mode, i.e.\ from a
syntactic point of view, to a semantic point of view.  What this
movement entailed in practice was a shift from syntactic explications
of concepts to semantic explications of concepts.  Thus, it is only
natural that having discarded the syntactic explication of mind-body
reduction, analytic philosophers would cast about for a semantic
explication of the idea.  Only, in this case, the very word
``reduction'' had so many negative associations that a new word was
needed.  To this end, analytic philosophers coopted the word
``supervenience.''  Thus Donald Davidson:
\begin{quote} Mental characteristics are in some sense dependent, or
  supervenient, on physical characteristics.  Such supervenience might
  be taken to mean that there cannot be two events alike in all
  physical respects but differing in some mental respect, or that an
  object cannot alter in some mental respect without altering in some
  physical respect. \citep{davidson} \end{quote} The idea expressed in
words here seems ripe for some kind of formalization.  If we could
speak of a domain $X$ of events, and if we could sort the features of
events into physical $\Sigma _p$ and $\Sigma _m$, then we could
formalize the supervenience thesis as saying that for any $x,y\in X$,
if $\phi (x)\lra \phi (y)$ for all physical features, then
$\psi (x)\lra \psi (y)$ for all mental features as well.

It must have seemed --- in the 1970s and 1980s --- that philosophical
progress had been made in moving from the thin semantic concept of
reduction to the thick semantic concept of supervenience.  Indeed, by
the time the 1990s rolled around, the word ``supervenience'' had
become something of a shibboleth in philosophical circles, and was
invoked frequently when philosophers encountered entities of
suspicious ontological provenence.  With the benefit of hindsight, we
are immediately suspicious when we hear that a shift from syntax to
semantics has transformed an implausible philosophical claim into a
plausible one.  Indeed, in this case, there is good reason to think
that the concept of supervenience is merely a dodge, and that if we
analyze it closely, it's nothing more than reducibility in sheep's
clothing.  In particular, the metaphysician's notion of supervenience
is really none other than the logician's notion of \emph{implicit
  definition}.  Moreover, \emph{Beth's theorem} entails that if a
predicate $r(x)$ is implicitly definable in terms of others
$p_1(x),\dots ,p_n(x)$, then there it is also explicitly definable in
terms of them.  In other words, supervenience is merely the semantic
mirror concept of the syntactic concept of reduction.  Accordingly, if
reductionism is philosophically implausible, then so is supervenience.

But is it really implausible to say that the mental is reducible to
the physical?  That was the conclusion of arguments put forward in the
1960s and 1970s by Hilary Putnam, Jerry Fodor, and several others who
were eagerly dismantling the remaining bits of the edifice of logical
positivism.  We won't stop here to review the arguments against
mind-brain reductionism, as interesting as they are, since that has
been done in many other places \citep[see][]{bickle-sep}.  We are
interested rather in John Bickle's \citeyearpar{bickle} claim that the
arguments against reduction are only effective against {\it syntactic}
accounts thereof --- and that a {\it semantic} account of reduction
doesn't fall prey to these objections.  Once again, the well-trained
logician will be immediately suspicious of such claims, as they
suggest that logical semantics some how moves us closer to the thing
in itself than logical syntax was able to do.  To the contrary, Bickle
has made the cardinal error of post-Tarskian analytic philosophers: to
view logical semantics as providing privileged language that ...

The present book attempts to emphasize the fundamental duality between
logical syntax and semantics.  If we are correct about this duality,
then it is {\it always} mistaken to think that semantic accounts of
concepts are more intrinsic, or that they allow us to break free of
human reliance on representations, or that they move us closer to the
``world'' side of the mind-world divide.  To view logical semantics as
the royal road to the {\it Ding an Sich} may be the cardinal sin of
post-Quinean technical analytic philosophy.

To the contrary, logical semantics is \dots wait for it \dots just
more mathematics.  Logical semantics can be used to model things in
the world, including people and their attempts to represent the world;
but logical semantics does not provide us with a representation-free
account of things. In particular, every problem and puzzle and
confusion that arises in logical syntax --- most notably, the problem
of language-dependence --- rears its ugly head again in logical
semantics.  If, for example, scientific antirealism doesn't make any
sense when explicated syntactically, then it's not going to help to
explicate it semantically.  (I happen to think that it {\it does} make
sense when explicated syntactically, but that is another issue.)

What I am saying here should not be taken as a criticism of attempts
to explicate concepts semantically.  In fact, I'll be the first to
grant that some concepts look more natural on the semantic side than
on the syntactic, or vice versa.  Nonetheless, we should be suspicious
of any claims that a philosophical thesis (e.g.\ physicalism,
antirealism, etc.) is untenable when explicated syntactically, but
becomes tenable when explicated semantically.

\section{Analytic truth} %% implicit definition, Gergonne, Poincare,
%% Hilbert

I fear to mention this topic, since it dominated so much of the
philosophical discussion of the 20th century, and since so much has
been written about it.  I can hardly imagine that I could say anything
that hasn't already been said, or even shown to be incoherent, as
philosophers seem to have explored every last quantum of logical space
on this issue.  In any case, my aspirations here are modest.  I merely
hope to raise awareness of a couple of issues that philosophers may
have forgotten --- especially as analytic philosophy has grown apart
from the exact sciences.

The 20th century's concern with ``analytic truth'' didn't arise in the
seminar rooms of philosophy departments --- or at least, not in
philosophy departments like the ones of today.  In fact, this concern
began rather with 19th century geometers, faced with two parallel
developments: (1) the discovery of non-euclidean geometries, and (2)
the need to raise the level of rigor in mathematical arguments.  These
two developments together led to clear disconnect between mathematical
language and the physical world.  In other words, one key outcome of
the development of modern mathematics was the {\it de-interpretation}
of mathematical terms such as ``number'' or ``line''.  These terms
were replaced by symbols that bore no intuitive connection to external
reality.

As a result of the de-interpretation of mathematical terms,
mathematicians breathed a collective sigh of relief.  For one, they
could set aside the dispute about ``which geometry is the right one?''
as based on a false presupposition, viz.\ that a theory of geometry
has a natural interpretation in the physical world.  At least
pragmatically speaking --- in terms of developments in mathematics ---
this development had extremely positive effects.  And we philosophers
shouldn't take these positive effects lightly.  Has philosophy made
progress in the past one hundred years?  Perhaps, and perhaps not.
But there is no question whatsoever that mathematics has been
explosively progressive, presenting an ever more elaborate ...

It was this de-interpretation of mathematical terms that gave rise to
the 20th century idea precisifiction of analytic truth as {\it truth
  by postulation}.  The consensus idea among the leading lights of
modern mathematics --- Hilbert, Pasch --- was that words such as
``line'' mean nothing more nor less than what axioms say of them.
Thus, it's simply not possible to write down false postulates about
lines.  There is no external standard against which to measure the
truth of these postulates.

%% implicit definition. Gergonne

From a more formal point of view, suppose that $\phi (t)$ denotes a
conjunction of axioms in which a term $t$ occurs.









\section{Realism and antirealism}


\section{Set theory as metatheory}


\section{Theoretical terms}

[[ TO DO :: Semantics as the middle man]]



\section{Notes}

\begin{itemize}
\item For Russell's program for rebuilding philosophy on the basis of
  formal logic, see \citep{russell-math,russell-le}.  Russell's idea
  was taken up by Wittgenstein, and was extensively developed by
  Carnap.  Nonetheless, Carnap first learned mathematical logic from
  Frege during his student years in Jena (1910--14). Carnap's personal
  recollections can be found in \citep{carnap-schilpp}.
\item In this chapter, my primary objective was to show the
  philosopher-in-training that there is a rich philosophical payoff
  for learning the metatheory of first-order logic: the better she
  understands the logic, the better she will understand the history of
  analytic philosophy, and the options going forward.  Although I've
  tried to be reasonably faithful to the historical record, I've been
  quite selective in focus.  The curious reader should consult more
  detailed studies, such as \cite{coffa,friedman1999,hylton,soames}.
\item Frege and Russell were early critics of Hilbert's view of
  implicit definition \cite[see e.g.][]{frege-hilbert}.  In contrast,
  \cite[I.7]{schlick} explicitly endorses Hilbert's view.  For
  Carnap's view, see \cite{park2012}.  The discussion later got
  muddled up in discussions of Ramsey sentences \cite[see
  e.g.][]{winnie-id,lewis-terms}, which some philosophers believe to
  have magical problem-solving power.  For an extended discussion of
  implicit definition and its relation to 20th century philosophical
  issues, see \cite{benmen}.
\item For more on the 19th century backdrop to analyticity, see
  \cite{coffa-geom}.
\item For overviews of logical methods in philosophy of science, see
  \cite{benthem-new,winnie,fraassen-new,leitgeb}.  The primary novelty
  of the present book is our use of category-theoretic methods.  We
  have tried not to mention category theory more than necessary, but
  we use it frequently.
  \end{itemize}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
